(window.webpackJsonp=window.webpackJsonp||[]).push([[57],{416:function(v,t,_){"use strict";_.r(t);var e=_(24),a=Object(e.a)({},(function(){var v=this,t=v.$createElement,_=v._self._c||t;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h1",{attrs:{id:"监控系统"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#监控系统"}},[v._v("#")]),v._v(" 监控系统")]),v._v(" "),_("p",[v._v("参考融云监控")]),v._v(" "),_("p",[_("a",{attrs:{href:"https://landscape.cncf.io/",target:"_blank",rel:"noopener noreferrer"}},[v._v("CNCF Cloud Native Interactive Landscape"),_("OutboundLink")],1)]),v._v(" "),_("p",[v._v("日志（logging，针对事件）、度量（metrics，针对可聚合数据）、调用链（tracing，针对请求）。毫无疑问，Metrcis和Logging是有数据重叠。下文将结合这些的基础知识与其在Turms领域中的运用。")]),v._v(" "),_("p",[v._v("Uptime健康检查")]),v._v(" "),_("p",[v._v("产品趋势趋于集成")]),v._v(" "),_("p",[v._v("成熟度阶梯")]),v._v(" "),_("table",[_("thead",[_("tr",[_("th"),v._v(" "),_("th",[v._v("数据收集")]),v._v(" "),_("th",[v._v("数据准备")]),v._v(" "),_("th",[v._v("数据分析")])])]),v._v(" "),_("tbody",[_("tr",[_("td",[v._v("高级")]),v._v(" "),_("td",[v._v("日志、指标、APM")]),v._v(" "),_("td",[v._v("大量结构化")]),v._v(" "),_("td",[v._v("人工分析、规则警告、机器学习、关联分析")])]),v._v(" "),_("tr",[_("td",[v._v("中级")]),v._v(" "),_("td",[v._v("日志、指标")]),v._v(" "),_("td",[v._v("少量结构化")]),v._v(" "),_("td",[v._v("人工分析、规则警告")])]),v._v(" "),_("tr",[_("td",[v._v("初级")]),v._v(" "),_("td",[v._v("日志集中化")]),v._v(" "),_("td",[v._v("不抽取")]),v._v(" "),_("td",[v._v("人工分析（全文检索分析）")])])])]),v._v(" "),_("p",[v._v("重收集，没做真正做到分析")]),v._v(" "),_("h3",{attrs:{id:"日志"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#日志"}},[v._v("#")]),v._v(" 日志")]),v._v(" "),_("p",[v._v("作用：用于记录离散的事件信息和各种对象的执行操作信息。例如，应用程序的调试信息或错误信息。它是我们诊断问题的重要依据；")]),v._v(" "),_("p",[v._v("代码产品：ELK，Splunk，日志易，阿里云日志服务等")]),v._v(" "),_("p",[v._v("在Turms中的体现：")]),v._v(" "),_("h3",{attrs:{id:"度量"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#度量"}},[v._v("#")]),v._v(" 度量")]),v._v(" "),_("p",[v._v("用于记录可聚合事件的数据集。例如，队列的当前深度可被定义为一个度量值，在元素入队或出队时被更新；HTTP 请求个数可被定义为一个计数器，新请求到来时进行累加。 通过立体化监控做到实时观测系统")]),v._v(" "),_("p",[v._v("代码产品：Prometheus,Borgmon等")]),v._v(" "),_("h3",{attrs:{id:"调用链"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#调用链"}},[v._v("#")]),v._v(" 调用链")]),v._v(" "),_("p",[v._v("服务化架构后服务之间存在复杂的调用关系，不同服务使用不同语言不同框架，一旦出现问题定界问题服务难度大，为此Google提出分布式跟踪系统，用于记录业务请求范围内的信息包括调用时间、调用接口、调用层次、调用结果等。例如，一次远程方法调用的执行过程(经过的微服务)和耗时。它是我们排查系统性能问题的利器")]),v._v(" "),_("p",[v._v("代码产品： Dapper ,Zipkin , X-ray(AWS),jaeger等")]),v._v(" "),_("p",[v._v("哪些函数栈，该请求处理时间是多少")]),v._v(" "),_("p",[v._v("健康检查")]),v._v(" "),_("p",[v._v("主动：注册中心")]),v._v(" "),_("p",[v._v("被动：/health接口")]),v._v(" "),_("p",[v._v("TODO：介绍下Spring Boot Actuator")]),v._v(" "),_("p",[v._v("鉴于各开发者对度量有着不同的要求，因此下面简单介绍下，Tumrs已经集成了的metrics：")]),v._v(" "),_("p",[v._v("TCP层面：https://projectreactor.io/docs/netty/release/reference/index.html#_metrics")]),v._v(" "),_("p",[v._v("开发者只需在application.yaml配置文件中简单配置，即可使用。")]),v._v(" "),_("p",[v._v("度量：")]),v._v(" "),_("p",[v._v("系统指标：CPU使用率、硬盘使用率、网络带宽等。不关注，由EC2负责")]),v._v(" "),_("p",[v._v("应用指标：API请求数、出错率、延迟、饱和度")]),v._v(" "),_("p",[v._v("业务指标：在线用户数")]),v._v(" "),_("p",[v._v("日志：可集中化、可全文搜索、可关联")]),v._v(" "),_("p",[v._v("链路最终：requestId")]),v._v(" "),_("h2",{attrs:{id:"日志-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#日志-2"}},[v._v("#")]),v._v(" 日志")]),v._v(" "),_("h3",{attrs:{id:"日志格式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#日志格式"}},[v._v("#")]),v._v(" 日志格式")]),v._v(" "),_("p",[v._v("必须包含四类元信息：\ntime: 日志产生时间，ISO8601格式\nlevel：日志等级， FATAL、ERROR、WARN、INFO、DEBUG\napp_id：应用id，用于标示日志来源，与公司服务树一致，全局唯一\ninstance_id：实例id，用于区分同一应用不同实例，格式业务方自行设定\n日志详细信息统一保存到log字段中。具体原因可查阅：https://softwareengineering.stackexchange.com/questions/312197/benefits-of-structured-logging-vs-basic-logging\n除上述字段之外，业务方也可以自行添加额外的字段。\njson的mapping应保持不变：key不能随意增加、变化，value的类型也应保持不变。")]),v._v(" "),_("p",[v._v('例如：{"log": "hello billions, write more", "level": "INFO", "app_id": "testapp111", "instance_id": "instance1", "time": "2017-08-04T15:59:01.607483", "id": 0}')]),v._v(" "),_("p",[v._v("现在JSON Layout也比较流行，但由于JSON做日志时的最大价值主要是统一不同项目组所负责的服务日志格式，Turms没有采用JSON。是因为：")]),v._v(" "),_("ol",[_("li",[_("p",[v._v("增加不必要的正反序列化耗时")])]),v._v(" "),_("li",[_("p",[v._v("Turms\n总的来说，用了JSON的Overhead时间可能比业务处理本身的时间还长。")]),v._v(" "),_("p",[v._v("没有采用Java中标准的toString实现是因为：？。当然，toString方便后期拓展，这就看团队意愿了。")])])]),v._v(" "),_("p",[v._v("调用链分析")]),v._v(" "),_("p",[v._v("2016-11-11 11:58:38.833  WARN [websocket-service,37e0966f0f3c3a65,37e0966f0f3c3a65,false] 89201 --- [nboundChannel-6] o.s.cloud.sleuth.util.ExceptionUtils     : Tried to detach trace span but it is not the current span: [Trace: 37e0966f0f3c3a65, Span: 37e0966f0f3c3a65, Parent: null, exportable:false]. You may have forgotten to close or detach null")]),v._v(" "),_("p",[v._v("□ appname:service-a/b，是设置的应用名称。\n□ traceId:7feec0479597d1b9, Spring Cloud Sleuth生成的TraceId，一次请求的唯一标识。\n□ spanId:578bef9ed3901d9b, Spring Cloud Sleuth生成的SpanId，标识一个基本的工作单元，此处是Feign进行的HTTP调用。\n□ exportable:false，是否将数据导出，如果只是想要在Span中封装一些操作并将其写日志时，此时就不需要将Span导出。")]),v._v(" "),_("p",[v._v("注意：Turms为保持日志的解析方式简单，异常堆栈的事件也是仅一行（普遍做法是多行，Filebeat也能解析多行日志）。")]),v._v(" "),_("p",[v._v("日志分类")]),v._v(" "),_("ol",[_("li",[_("p",[v._v("监控日志System Log（性能预警等）：API：beginTime, endTime, elapsedTime\n响应时间、调用次数、内存可用率、CPU使用率、网络连通性。")])]),v._v(" "),_("li"),v._v(" "),_("li",[_("p",[v._v("正确性、可用性、正确率、可用率、错误总时长、错误总次数、故障总时长、故障总次数、平均可用率、平均正确率、故障率、响应时间、平均响应时间。")]),v._v(" "),_("p",[v._v("程序运行状况：记录程序的运行状况，特别是非预期的行为、异常情况，这种日志，主要是给开发、维护人员使用。什么时候记录，记录什么内容，完全取决于开发人员，开发者具有高度自主性。本文讨论的主要也是指这种类型的日志，因为作为一个服务端开发、运维人员，程序运行日志往往是解决线上问题的救命稻草。")]),v._v(" "),_("p",[v._v("（metrics）系统、机器状况：比如网络请求、系统CPU、内存、IO使用情况等等，这种日志主要是给运维人员使用，生成各种更直观的展现形式，在系统出问题的时候报警。用ELK，还是prometheus？")])]),v._v(" "),_("li",[_("p",[v._v("业务日志（用户行为分析.收集用户行为日志https://www.jianshu.com/p/3f8b02aba670）")]),v._v(" "),_("p",[v._v("Audit Log")])]),v._v(" "),_("li",[_("p",[v._v("统计日志。记录用户行为：这种类型的日志，记录用户的操作行为，用于大数据分析，比如监控、风控、推荐等等。这种日志，一般是给其他团队分析使用，而且可能是多个团队，因此一般会有一定的格式要求，开发者应该按照这个格式来记录，便于其他团队的使用。当然，要记录哪些行为、操作，一般也是约定好的，因此，开发者主要是执行的角色。")]),v._v(" "),_("p",[v._v("特别注意的是：用户的行为日志并不是由turms-gateway进行收集的，而是由下游的turms服务端收集的。这么做的原因是：为了达到最为高效的性能，减少不必要的开销，turms-gateway只会从堆外内存中读取少量必要内容来记录用户行为，并不会解析整个用户请求。如果只是为了记录用户行为就将堆外内存全部拷贝到堆内就过于浪费了。")])])]),v._v(" "),_("p",[v._v("日志归档")]),v._v(" "),_("p",[v._v("策略：仅支持本地归档")]),v._v(" "),_("p",[v._v("原计划是要支持三种可选策略：本地归档、MongoDB归档、同时进行本地归档与MongoDB归档。但由于本地归档是大中型项目的最终归宿，并且为了避免部分用户对直接的MongoDB归档产生依赖，导致该类用户后期难以调整。")]),v._v(" "),_("p",[v._v("支持MongoDB归档、支持同时本地归档与MongoDB归档（优先MongoDB归档，如果失败则本地归档）。")]),v._v(" "),_("p",[v._v("注意：MongoDB只是存储跟日志有关的对象模型，实际并不是存储日志")]),v._v(" "),_("p",[v._v("对于本地Turms不提供")]),v._v(" "),_("p",[v._v("如果有其他定制需求，请在XXX处自定义配置")]),v._v(" "),_("p",[v._v("背景")]),v._v(" "),_("p",[v._v("早期Turms架构为了方便快速做基础数据分析功能，直接将用户操作行为与管理员操作行为直接写入MongoDB。这样做有X个缺点，一是实现不灵活，写死了直接日志存储的实现，用户如果想自研接入Kafka或大数据技术栈的话，还需要重构这块代码。二是日志存储实现不统一，因为大部分日志默认只会存储在本地。三是增加了一个网络故障风险，如果需要健全的日志体系，还需要在发现网络故障的时候，将日志存储在本地，实现麻烦。当然优点就是开发者可以快速体验Turms开箱即用的数据分析功能。但对于中大项目而言，数据分析更适合交由大数据技术栈专门实现，否则很难在满足自身定制需求与高效实现中找到平衡。")]),v._v(" "),_("p",[v._v("因此现在Turms的日志存储采用标准的中大项目实现，即Turms只进行本地的日志存储操作，具体的日志采集工作交给开发者自行实现（如采用FileBeat定时进行日志采集，并将数据传给Logtash做解析，解析完后再将数据传给Elasticsearch做存储与分析，最后通过Kibana展示）")]),v._v(" "),_("p",[v._v("https://softwareengineering.stackexchange.com/questions/312197/benefits-of-structured-logging-vs-basic-logging")]),v._v(" "),_("p",[v._v("日志采样")]),v._v(" "),_("p",[v._v("对日志而言，“大量数据中的一小部分就足以进行问题排查和趋势发现”，与研发和运维进行沟通，这个观点也得到认同。日志采样以app_id为维度，INFO级别以下日志按照比例进行随机采样，WARN以上日志全部保留")]),v._v(" "),_("p",[v._v("由于要获取日志内的app_id字段，如果直接进行json解析， cpu消耗将非常之高。后续我们改进为字符查找（bytes.Index ）")]),v._v(" "),_("p",[v._v("日志采集Filebeat, Graylog, Fluentd")]),v._v(" "),_("p",[v._v("日志解析")]),v._v(" "),_("p",[v._v("https://www.elastic.co/guide/en/beats/filebeat/master/multiline-examples.html")]),v._v(" "),_("p",[v._v("参考标准流程")]),v._v(" "),_("p",[v._v("Alert——Dashboard——Adhoc Query——Log Aggregator——Distributed Tracing——Fix")])])}),[],!1,null,null,null);t.default=a.exports}}]);