(window.webpackJsonp=window.webpackJsonp||[]).push([[97],{455:function(v,_,t){"use strict";t.r(_);var e=t(24),a=Object(e.a)({},(function(){var v=this,_=v.$createElement,t=v._self._c||_;return t("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[t("h1",{attrs:{id:"可观察性体系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可观察性体系"}},[v._v("#")]),v._v(" 可观察性体系")]),v._v(" "),t("h2",{attrs:{id:"重要性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重要性"}},[v._v("#")]),v._v(" 重要性")]),v._v(" "),t("p",[v._v("尽管可观察性体系的建设如此重要，但仍有不少的团队完全没有监控与运维意识（甚至很多开源即时通讯项目也完全没有可观察性体系建设的意识），只有当产品在生产环境运行时出现严重事故，并造成经济损失了之后，才开始关注产品的可观察性体系建设。因此Turms服务端默认开启各种必要且实现高效的监控功能。一方面，为将来数据挖掘与用户行为分析做准备。另一方面，为开发运维团队提供实际监控的可能，并在危机时刻绝渡逢舟。")]),v._v(" "),t("p",[v._v("另外值得一提的是，Turms还支持以下特性（以下特性可能会在危急关头帮您的团队渡过难关）：")]),v._v(" "),t("ol",[t("li",[v._v("Turms服务端大量的配置都支持零停机更新")]),v._v(" "),t("li",[v._v("Turms的架构允许Turms服务端进行金丝雀发布")]),v._v(" "),t("li",[v._v("（TODO）turms-admin支持可视化监控集群状态与管理集群")])]),v._v(" "),t("h2",{attrs:{id:"_3-1体系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1体系"}},[v._v("#")]),v._v(" 3+1体系")]),v._v(" "),t("p",[v._v("3+1体系指的是：Turms提供三个纬度的监控数据与指标，以及一套可视化的监控系统（即：turms-admin）。")]),v._v(" "),t("p",[v._v("注意：")]),v._v(" "),t("ul",[t("li",[v._v("监控数据的生成与是否采用turms-admin项目无关，turms-admin仅是可选的可视化监控系统。")]),v._v(" "),t("li",[v._v("turms-admin与商用监控系统不冲突，二者相辅相成。")])]),v._v(" "),t("h3",{attrs:{id:"三个维度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#三个维度"}},[v._v("#")]),v._v(" 三个维度")]),v._v(" "),t("p",[v._v("Turms提供比较全面的监控数据，概括来说，主要包括了以下三个纬度：")]),v._v(" "),t("ul",[t("li",[v._v("日志（针对事件）：共提供了三大类日志：监控日志、业务日志、统计日志。")]),v._v(" "),t("li",[v._v("度量（针对可聚合数据）。包括系统允许状态的实时监控信息，以及业务相关数据的实时信息。")]),v._v(" "),t("li",[v._v("简易的链路追踪。Turms不完全遵循OpenTracing链路追踪规范，这是因为链路追踪的标准规范对于Turms架构来说太重，也无标准的不做过度设计，")])]),v._v(" "),t("p",[v._v("补充：Turms服务端自身会在实现高效的前提下尽可能提供更多监控数据，但对于一些尽管常见却对性能影响较大的数据不予提供（如：日活）。对于这类拓展功能，您可以通过Turms的日志与度量离线或实时分析实现。")]),v._v(" "),t("ol",[t("li",[t("p",[v._v("实时运行状态监控。Turms默认提供HTTP接口来查询状态数据（默认关闭JMX）。默认启用的接口包括：info、health、env、heapdump、threaddump、metrics、prometheus。")]),v._v(" "),t("p",[v._v("另外Turms依靠Spring Boot Actuator实现，如果您想自行配置具体参数，可查阅该手册"),t("a",{attrs:{href:"https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html",target:"_blank",rel:"noopener noreferrer"}},[v._v("Spring Boot Actuator"),t("OutboundLink")],1)])]),v._v(" "),t("li",[t("p",[v._v("日志（logging，针对事件）")])]),v._v(" "),t("li",[t("p",[v._v("度量（metrics，针对可聚合数据）")])]),v._v(" "),t("li",[t("p",[v._v("简易链路追踪（）。")])])]),v._v(" "),t("p",[v._v("二层：常见的即时通讯相关业务统计（拓展功能。将部分度量数据定时落地后，Overhead非常小但功能非常实用），请查阅"),t("a",{attrs:{href:""}},[v._v("asdasdasd")])]),v._v(" "),t("p",[v._v("注意：由于Turms的服务间不存在依赖关系，因此不对RPC进行链路追踪")]),v._v(" "),t("h2",{attrs:{id:"开箱即用的业务统计指标"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#开箱即用的业务统计指标"}},[v._v("#")]),v._v(" 开箱即用的业务统计指标")]),v._v(" "),t("h3",{attrs:{id:"采集对象"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#采集对象"}},[v._v("#")]),v._v(" 采集对象")]),v._v(" "),t("p",[v._v("turms与turms-gateway自身只对满足以下条件的指标进行统计：")]),v._v(" "),t("ol",[t("li",[v._v("统计实现基于非CPU密集型算法，并对多线程友好，以保证算法实现对性能几乎无影响")]),v._v(" "),t("li",[v._v("如果该指标需要在集群间进行聚合操作，则该RPC请求Payload不能过大（如数十KB），并同时满足条件①，否则定期的统计工作会造成性能波动")])]),v._v(" "),t("p",[v._v("以上的反例就是需要采用Hyperloglog、CPC等基数算法实现（不管是通过本地代码实现，还是调用远程Redis服务端来实现）的指标统计。")]),v._v(" "),t("p",[v._v("特别值得一提的是：由于turms与turms-gateway自身支持的统计指标实现都非常高效，推荐您保持默认的开启状态。")]),v._v(" "),t("p",[v._v("对于被排除在外的其他常见统计指标（如DAU日活跃用户DAU），由于该类指标的统计对正常的业务事务处理吞吐量有较大影响。因此turms与turms-gateway不进行也不应该进行对这些业务指标的统计工作。该类指标将在之后交由专门的大数据分析系统turms-data来进行采集、分析、统计与存储工作。")]),v._v(" "),t("p",[v._v("根据监控、业务统计分析做设计")]),v._v(" "),t("p",[v._v("参考融云监控")]),v._v(" "),t("p",[t("a",{attrs:{href:"https://landscape.cncf.io/",target:"_blank",rel:"noopener noreferrer"}},[v._v("CNCF Cloud Native Interactive Landscape"),t("OutboundLink")],1)]),v._v(" "),t("p",[v._v("日志（logging，针对事件）、度量（metrics，针对可聚合数据）、调用链（tracing，针对请求）。毫无疑问，Metrcis和Logging是有数据重叠。下文将结合这些的基础知识与其在Turms领域中的运用。")]),v._v(" "),t("p",[v._v("Uptime健康检查")]),v._v(" "),t("p",[v._v("产品趋势趋于集成")]),v._v(" "),t("p",[v._v("成熟度阶梯")]),v._v(" "),t("table",[t("thead",[t("tr",[t("th"),v._v(" "),t("th",[v._v("数据收集")]),v._v(" "),t("th",[v._v("数据准备")]),v._v(" "),t("th",[v._v("数据分析")])])]),v._v(" "),t("tbody",[t("tr",[t("td",[v._v("高级")]),v._v(" "),t("td",[v._v("日志、指标、APM")]),v._v(" "),t("td",[v._v("大量结构化")]),v._v(" "),t("td",[v._v("人工分析、规则警告、机器学习、关联分析")])]),v._v(" "),t("tr",[t("td",[v._v("中级")]),v._v(" "),t("td",[v._v("日志、指标")]),v._v(" "),t("td",[v._v("少量结构化")]),v._v(" "),t("td",[v._v("人工分析、规则警告")])]),v._v(" "),t("tr",[t("td",[v._v("初级")]),v._v(" "),t("td",[v._v("日志集中化")]),v._v(" "),t("td",[v._v("不抽取")]),v._v(" "),t("td",[v._v("人工分析（全文检索分析）")])])])]),v._v(" "),t("p",[v._v("重收集，没做真正做到分析")]),v._v(" "),t("p",[v._v("https://zhuanlan.zhihu.com/p/225215407")]),v._v(" "),t("h3",{attrs:{id:"日志"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#日志"}},[v._v("#")]),v._v(" 日志")]),v._v(" "),t("p",[v._v("作用：用于记录离散的事件信息和各种对象的执行操作信息。例如，应用程序的调试信息或错误信息。它是我们诊断问题的重要依据；")]),v._v(" "),t("p",[v._v("代码产品：ELK，Splunk，日志易，阿里云日志服务等")]),v._v(" "),t("p",[v._v("Turms默认将XX分为X个文件，如果需要合并，因此如果您有合并的需求，您应该在日志处理中心")]),v._v(" "),t("p",[v._v("线上数据 -> flume -> kafka -> storm\n大多数可用的日志记录框架由以下四个组件组成：")]),v._v(" "),t("p",[v._v("日志追加程序 负责从应用程序进程中收集日志（在整个群集中运行），并确保将日志发送到下游进行提取。有各种追加程序可用，例如文件、控制台、数据库、消息队列等。")]),v._v(" "),t("p",[v._v("日志提取 是获取由附加程序收集的日志并将其放入存储层的步骤。这通常意味着清理和转换日志，然后将它们编入搜索引擎以方便用户使用。")]),v._v(" "),t("p",[v._v("存储和搜索层 通常是一个分布式搜索引擎，或者更简单的情况下，分布在日志存储和访问文件系统或数据库。")]),v._v(" "),t("p",[v._v("仪表板与警报层就座于存储层的顶部。它为用户提供了交互式图形界面，用于搜索日志和可视化重要信息。它还通常包括警报功能。")]),v._v(" "),t("p",[v._v("a) Apache Kafka日志附加程序，用于可伸缩和低延迟的日志收集")]),v._v(" "),t("p",[v._v("b) 使用Apache Flink进行日志提取、索引编制和自定义监视")]),v._v(" "),t("p",[v._v("c) Apache Solr用于存储和搜索功能")]),v._v(" "),t("p",[v._v("d) Hue用于记录仪表板")]),v._v(" "),t("p",[v._v("要解决的第一个挑战是将日志从生产应用程序收集到传输到摄取器组件。通常，有几种方法可以解决此问题，每种方法都有其起伏。")]),v._v(" "),t("p",[v._v("通过直接将日志索引到存储层，我们可以完全跳过整个日志收集/传输步骤。从理论上讲，这将给我们带来非常低的延迟，但是它将日志记录与获取和存储本身紧密结合在一起，从而导致系统脆弱：")]),v._v(" "),t("p",[v._v("摄取/存储逻辑的更改要求日志记录应用程序的更改")]),v._v(" "),t("p",[v._v("存储层的停机时间可能会影响正在运行的应用程序（或丢失日志）")]),v._v(" "),t("p",[v._v("存储系统本身可能无法扩展到传入连接的数量")]),v._v(" "),t("p",[v._v("由于这些原因，我们强烈希望将日志记录与摄取分开。鉴于这个关键的设计决策，我们仍然有不同的方法来将日志消息发送到日志接收器。")]),v._v(" "),t("p",[v._v("默认情况下，大多数应用程序都会写入日志文件，这些文件存储在主机本地。可以定期收集这些文件，但是不幸的是，随着越来越多的应用程序，它变得相当复杂，并且它也不能为我们的实时需求提供足够的延迟。")]),v._v(" "),t("p",[v._v("在Turms中的体现：")]),v._v(" "),t("h3",{attrs:{id:"度量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#度量"}},[v._v("#")]),v._v(" 度量")]),v._v(" "),t("p",[v._v("用于记录可聚合事件的数据集。例如，队列的当前深度可被定义为一个度量值，在元素入队或出队时被更新；HTTP 请求个数可被定义为一个计数器，新请求到来时进行累加。 通过立体化监控做到实时观测系统")]),v._v(" "),t("p",[v._v("代码产品：Prometheus,Borgmon等")]),v._v(" "),t("p",[v._v("其实监控不仅仅是体现在可以实时掌握系统运行情况，及时报警这些。而且监控所采集的数据，在以下几个方面是有价值的")]),v._v(" "),t("ul",[t("li",[v._v("资源的审计和计费。这个需要保存一年甚至多年的数据的。")]),v._v(" "),t("li",[v._v("故障责任的追查")]),v._v(" "),t("li",[v._v("对过去复盘，对现在实时观察，对未来趋势分析。后续的分析和挖掘，甚至是利用AI，可以实现报警规则的设定的智能化，故障的根因分析以及预测某个应用的qps的趋势，提前HPA等，当然这是现在流行的AIOPS范畴了。")])]),v._v(" "),t("h3",{attrs:{id:"调用链"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#调用链"}},[v._v("#")]),v._v(" 调用链")]),v._v(" "),t("p",[v._v("服务化架构后服务之间存在复杂的调用关系，不同服务使用不同语言不同框架，一旦出现问题定界问题服务难度大，为此Google提出分布式跟踪系统，用于记录业务请求范围内的信息包括调用时间、调用接口、调用层次、调用结果等。例如，一次远程方法调用的执行过程(经过的微服务)和耗时。它是我们排查系统性能问题的利器")]),v._v(" "),t("p",[v._v("代码产品： Dapper ,Zipkin , X-ray(AWS),jaeger等")]),v._v(" "),t("p",[v._v("哪些函数栈，该请求处理时间是多少")]),v._v(" "),t("p",[v._v("健康检查")]),v._v(" "),t("p",[v._v("主动：注册中心")]),v._v(" "),t("p",[v._v("被动：/health接口")]),v._v(" "),t("p",[v._v("TODO：介绍下Spring Boot Actuator")]),v._v(" "),t("p",[v._v("鉴于各开发者对度量有着不同的要求，因此下面简单介绍下，Tumrs已经集成了的metrics：")]),v._v(" "),t("p",[v._v("TCP层面：https://projectreactor.io/docs/netty/release/reference/index.html#_metrics")]),v._v(" "),t("p",[v._v("开发者只需在application.yaml配置文件中简单配置，即可使用。")]),v._v(" "),t("p",[v._v("度量：")]),v._v(" "),t("p",[v._v("系统指标：CPU使用率、硬盘使用率、网络带宽等。不关注，由EC2负责")]),v._v(" "),t("p",[v._v("应用指标：API请求数、出错率、延迟、饱和度")]),v._v(" "),t("p",[v._v("业务指标：在线用户数")]),v._v(" "),t("p",[v._v("日志：可集中化、可全文搜索、可关联")]),v._v(" "),t("p",[v._v("链路最终：requestId")]),v._v(" "),t("h2",{attrs:{id:"日志-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#日志-2"}},[v._v("#")]),v._v(" 日志")]),v._v(" "),t("h3",{attrs:{id:"日志格式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#日志格式"}},[v._v("#")]),v._v(" 日志格式")]),v._v(" "),t("p",[v._v("必须包含四类元信息：\ntime: 日志产生时间，ISO8601格式\nlevel：日志等级， FATAL、ERROR、WARN、INFO、DEBUG\napp_id：应用id，用于标示日志来源，与公司服务树一致，全局唯一\ninstance_id：实例id，用于区分同一应用不同实例，格式业务方自行设定\n日志详细信息统一保存到log字段中。具体原因可查阅：https://softwareengineering.stackexchange.com/questions/312197/benefits-of-structured-logging-vs-basic-logging\n除上述字段之外，业务方也可以自行添加额外的字段。\njson的mapping应保持不变：key不能随意增加、变化，value的类型也应保持不变。")]),v._v(" "),t("p",[v._v('例如：{"log": "hello billions, write more", "level": "INFO", "app_id": "testapp111", "instance_id": "instance1", "time": "2017-08-04T15:59:01.607483", "id": 0}')]),v._v(" "),t("p",[v._v("现在JSON Layout也比较流行，但由于JSON做日志时的最大价值主要是统一不同项目组所负责的服务日志格式，Turms没有采用JSON。是因为：")]),v._v(" "),t("ol",[t("li",[t("p",[v._v("增加不必要的正反序列化耗时")])]),v._v(" "),t("li",[t("p",[v._v("Turms\n总的来说，用了JSON的Overhead时间可能比业务处理本身的时间还长。")]),v._v(" "),t("p",[v._v("没有采用Java中标准的toString实现是因为：？。当然，toString方便后期拓展，这就看团队意愿了。")])])]),v._v(" "),t("p",[v._v("调用链分析")]),v._v(" "),t("p",[v._v("2016-11-11 11:58:38.833  WARN [websocket-service,37e0966f0f3c3a65,37e0966f0f3c3a65,false] 89201 --- [nboundChannel-6] o.s.cloud.sleuth.util.ExceptionUtils     : Tried to detach trace span but it is not the current span: [Trace: 37e0966f0f3c3a65, Span: 37e0966f0f3c3a65, Parent: null, exportable:false]. You may have forgotten to close or detach null")]),v._v(" "),t("p",[v._v("□ appname:service-a/b，是设置的应用名称。\n□ traceId:7feec0479597d1b9, Spring Cloud Sleuth生成的TraceId，一次请求的唯一标识。\n□ spanId:578bef9ed3901d9b, Spring Cloud Sleuth生成的SpanId，标识一个基本的工作单元，此处是Feign进行的HTTP调用。\n□ exportable:false，是否将数据导出，如果只是想要在Span中封装一些操作并将其写日志时，此时就不需要将Span导出。")]),v._v(" "),t("p",[v._v("注意：Turms为保持日志的解析方式简单，异常堆栈的事件也是仅一行（普遍做法是多行，Filebeat也能解析多行日志）。")]),v._v(" "),t("p",[v._v("日志分类")]),v._v(" "),t("ol",[t("li",[t("p",[v._v("系统日志System Log（性能预警等）：API：beginTime, endTime, elapsedTime\n响应时间、调用次数、内存可用率、CPU使用率、网络连通性。")]),v._v(" "),t("p",[v._v("正确性、可用性、正确率、可用率、错误总时长、错误总次数、故障总时长、故障总次数、平均可用率、平均正确率、故障率、响应时间、平均响应时间。")])]),v._v(" "),t("li",[t("p",[v._v("应用日志：程序运行状况：记录程序的运行状况，特别是非预期的行为、异常情况，这种日志，主要是给开发、维护人员使用。什么时候记录，记录什么内容，完全取决于开发人员，开发者具有高度自主性。本文讨论的主要也是指这种类型的日志，因为作为一个服务端开发、运维人员，程序运行日志往往是解决线上问题的救命稻草。")]),v._v(" "),t("p",[v._v("（metrics）系统、机器状况：比如网络请求、系统CPU、内存、IO使用情况等等，这种日志主要是给运维人员使用，生成各种更直观的展现形式，在系统出问题的时候报警。用ELK，还是prometheus？")])]),v._v(" "),t("li",[t("p",[v._v("业务日志（用户行为分析.收集用户行为日志https://www.jianshu.com/p/3f8b02aba670）")]),v._v(" "),t("p",[v._v("Audit Log")])]),v._v(" "),t("li",[t("p",[v._v("统计日志。记录用户行为：这种类型的日志，记录用户的操作行为，用于大数据分析，比如监控、风控、推荐等等。这种日志，一般是给其他团队分析使用，而且可能是多个团队，因此一般会有一定的格式要求，开发者应该按照这个格式来记录，便于其他团队的使用。当然，要记录哪些行为、操作，一般也是约定好的，因此，开发者主要是执行的角色。")]),v._v(" "),t("p",[v._v("特别注意的是：用户的行为日志并不是由turms-gateway进行收集的，而是由下游的turms服务端收集的。这么做的原因是：为了达到最为高效的性能，减少不必要的开销，turms-gateway只会从堆外内存中读取少量必要内容来记录用户行为，并不会解析整个用户请求。如果只是为了记录用户行为就将堆外内存全部拷贝到堆内就过于浪费了。")])])]),v._v(" "),t("p",[v._v("日志归档")]),v._v(" "),t("p",[v._v("策略：仅支持本地归档")]),v._v(" "),t("p",[v._v("原计划是要支持三种可选策略：本地归档、MongoDB归档、同时进行本地归档与MongoDB归档。但由于本地归档是大中型项目的最终归宿，并且为了避免部分用户对直接的MongoDB归档产生依赖，导致该类用户后期难以调整。")]),v._v(" "),t("p",[v._v("支持MongoDB归档、支持同时本地归档与MongoDB归档（优先MongoDB归档，如果失败则本地归档）。")]),v._v(" "),t("p",[v._v("注意：MongoDB只是存储跟日志有关的对象模型，实际并不是存储日志")]),v._v(" "),t("p",[v._v("对于本地Turms不提供")]),v._v(" "),t("p",[v._v("如果有其他定制需求，请在XXX处自定义配置")]),v._v(" "),t("p",[v._v("背景")]),v._v(" "),t("p",[v._v("早期Turms架构为了方便快速做基础数据分析功能，直接将用户操作行为与管理员操作行为直接写入MongoDB。这样做有X个缺点，一是实现不灵活，写死了直接日志存储的实现，用户如果想自研接入Kafka或大数据技术栈的话，还需要重构这块代码。二是日志存储实现不统一，因为大部分日志默认只会存储在本地。三是增加了一个网络故障风险，如果需要健全的日志体系，还需要在发现网络故障的时候，将日志存储在本地，实现麻烦。当然优点就是开发者可以快速体验Turms开箱即用的数据分析功能。但对于中大项目而言，数据分析更适合交由大数据技术栈专门实现，否则很难在满足自身定制需求与高效实现中找到平衡。")]),v._v(" "),t("p",[v._v("因此现在Turms的日志存储采用标准的中大项目实现，即Turms只进行本地的日志存储操作，具体的日志采集工作交给开发者自行实现（如采用FileBeat定时进行日志采集，并将数据传给Logtash做解析，解析完后再将数据传给Elasticsearch做存储与分析，最后通过Kibana展示）")]),v._v(" "),t("p",[v._v("https://softwareengineering.stackexchange.com/questions/312197/benefits-of-structured-logging-vs-basic-logging")]),v._v(" "),t("p",[v._v("日志采样")]),v._v(" "),t("p",[v._v("对日志而言，“大量数据中的一小部分就足以进行问题排查和趋势发现”，与研发和运维进行沟通，这个观点也得到认同。日志采样以app_id为维度，INFO级别以下日志按照比例进行随机采样，WARN以上日志全部保留")]),v._v(" "),t("p",[v._v("由于要获取日志内的app_id字段，如果直接进行json解析， cpu消耗将非常之高。后续我们改进为字符查找（bytes.Index ）")]),v._v(" "),t("p",[v._v("日志采集Filebeat, Graylog, Fluentd")]),v._v(" "),t("p",[v._v("日志解析")]),v._v(" "),t("p",[v._v("https://www.elastic.co/guide/en/beats/filebeat/master/multiline-examples.html")]),v._v(" "),t("p",[v._v("参考标准流程")]),v._v(" "),t("p",[v._v("Alert——Dashboard——Adhoc Query——Log Aggregator——Distributed Tracing——Fix")])])}),[],!1,null,null,null);_.default=a.exports}}]);